{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec13bf60-112b-44c3-8e45-297056956465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOP 'GCMS-6.pdf' has been hidden.\n",
      "Step 1: Loading documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "invalid pdf header: b'\\r\\n%PD'\n",
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 45 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Splitting documents into chunks...\n",
      "Step 3: Adding chunks to Chroma database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roxan\\AppData\\Local\\Temp\\ipykernel_9588\\3005845537.py:41: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  return OpenAIEmbeddings(openai_api_key=API_KEY)\n",
      "C:\\Users\\roxan\\AppData\\Local\\Temp\\ipykernel_9588\\3005845537.py:35: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(persist_directory=CHROMA_PATH, embedding_function=get_embedding_function())\n",
      "C:\\Users\\roxan\\AppData\\Local\\Temp\\ipykernel_9588\\3005845537.py:37: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Generating SOP for an instrument...\n",
      "Generating section: Scope\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roxan\\AppData\\Local\\Temp\\ipykernel_9588\\3005845537.py:98: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  model = ChatOpenAI(model=\"gpt-4\", openai_api_key=API_KEY)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating section: Background\n",
      "Generating section: Safety\n",
      "Generating section: Materials Required\n",
      "Generating section: Standards and Controls\n",
      "Generating section: Calibration\n",
      "Generating section: Procedures\n",
      "Generating section: Sampling\n",
      "Generating section: Calculations\n",
      "Generating section: Uncertainty of Measurement\n",
      "Generating section: Limitations\n",
      "Generating section: Documentation\n",
      "Generating section: References\n",
      "SOP successfully saved to Generated_SOP_for_Gas_Chromatography.docx\n",
      "SOP generation completed.\n",
      "Similarity score between generated and actual SOP: 0.83\n"
     ]
    }
   ],
   "source": [
    "#Updated prompt ... 25 November\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import fitz  # PyMuPDF for PDF processing\n",
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from docx import Document as WordDocument\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "CHROMA_PATH = \"chroma\"  # Path to Chroma database\n",
    "DATA_PATH = \"SOPS\"  # Path to SOPS directory\n",
    "HIDDEN_SOP = \"GCMS-6.pdf\"  # Name of the hidden SOP file\n",
    "MANUAL_FILE = \"c10g-e080.pdf\"  # Manual file\n",
    "OUTPUT_FILE = \"Generated_SOP_for_Gas_Chromatography.docx\"  # Output file\n",
    "API_KEY = \"private key\"\n",
    "\n",
    "# Step 1: Load documents\n",
    "def load_documents():\n",
    "    document_loader = PyPDFDirectoryLoader(DATA_PATH)\n",
    "    return document_loader.load()\n",
    "\n",
    "# Step 2: Split documents into chunks\n",
    "def split_documents(documents: list[Document]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=80, length_function=len)\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "# Step 3: Create or update Chroma database\n",
    "def add_to_chroma(chunks: list[Document]):\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=get_embedding_function())\n",
    "    db.add_documents(chunks)\n",
    "    db.persist()\n",
    "\n",
    "# Embedding function\n",
    "def get_embedding_function():\n",
    "    return OpenAIEmbeddings(openai_api_key=API_KEY)\n",
    "\n",
    "# Step 4: Generate a single SOP section\n",
    "def generate_sop_section(query_text: str, manual_file: str, section: str):\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=get_embedding_function())\n",
    "\n",
    "    # Retrieve relevant chunks\n",
    "    results = db.similarity_search_with_score(query_text, k=3)\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _ in results])\n",
    "\n",
    "    # Extract manual content\n",
    "    manual_text = extract_manual_content(manual_file, max_pages=10)\n",
    "    context_text += f\"\\n\\nManual Content:\\n{manual_text[:2000]}\"  # Include snippet of manual content\n",
    "\n",
    "    # Generate the section\n",
    "    prompt = f\"\"\"\n",
    "     # Updated prompt\n",
    "    prompt = f\"\"\n",
    "    Include comprehensive details for each section, including examples, explanations, and visuals. Don't summarize the details and keep the ideas unique and not redundant. Use step-by-step style in writing the process. Dont ask the user to refer to manufacture manual like saying “.Follow the manufacturer’s guidelines for calibration procedures” \n",
    "\n",
    "Structure: \n",
    "\n",
    "    1. Scope: Defines the purpose and applicability of the procedure, Listing all  uses , applications and  analysis methods that could be done on this instrument, such as analyzing air samples, tobacco content, or hydrocarbons in automotive exhaust.  Specifies the sample types that instrument can measure , the detection limit in (mg/Kg) and the method spike recovery , if applicable. Defines the exclusions. Use bullet point style of writing.  \n",
    "\n",
    "    2. Background: Provides context or rationale for the method being standardized, reference related research or industry needs.  Explain the meaning of the instrument signals to help the user understand and correlate the analysis. List the abbreviation and definitions in a tabular format. List the previous models of the same device.  \n",
    "\n",
    "    3. Safety: describe point by point all safety precautions, including General precaution, operation precautions and list the personal protective equipment's (PPE) needed, Listing all possible hazardous chemicals used with this instrument. Describe step-by-stepwaste disposal protocols. Use the following paragraph between square brackets as an example for  \n",
    "\n",
    "[General laboratory precautions  \n",
    "\n",
    "Avoid leaks in the carrier gas lines. Use leak-checking equipment to periodically check for hydrogen leaks. • Eliminate from your laboratory as many ignition sources as possible (for example, open flames, devices that can spark and sources of static electricity). • Do not allow hydrogen from a high pressure cylinder to vent directly to atmosphere (danger of self-ignition). • Use a hydrogen generator instead of bottled hydrogen. Operating precautions • Turn off the hydrogen at its source every time you shut down the GC or MS. • Do not use hydrogen as a collision cell gas. Turn off the hydrogen at its source every time you vent the MS (do not heat the capillary column without carrier gas flow). • Turn off the hydrogen at its source every time shutoff valves in the MS are closed (do not heat the capillary column without carrier gas flow). • Turn off the hydrogen at its source if a power failure occurs. • If a power failure occurs while the GC/MS system is unattended, even if the system has restarted by itself:  Immediately turn off the hydrogen at its source.  Turn off the GC.  Turn off the MS and allow it to cool for 1 hour.  Eliminate all potential sources of ignition in the room.  Open the vacuum manifold of the MS to atmosphere.  Wait at least 10 minutes to allow any hydrogen to dissipate.  Start up the GC and MS as normal. When using hydrogen gas, check the system for leaks to prevent possible fire and explosion hazards based on local Environmental Health and Safety (EHS) requirements. Always check for leaks after changing a tank or servicing the gas lines. Always make sure the vent line is vented into a fume hood.] \n",
    "\n",
    " \n",
    "\n",
    "   4. Materials and Equipment: First, Explain in bullets all the instruments' parts and auxiliary equipment. Include samples and consumables materials in two sections.  Lists all necessary reagents, solvents, instrumentation, and ancillary tools required for conducting the procedure. Write it in a bullets style.  \n",
    "\n",
    "    5. Standards and Calibration: Details the required reference materials, standards for quality control, and steps for instrument calibration to ensure accuracy. \n",
    "\n",
    "    6. Procedure: Offers step-by-step instructions for conducting the analysis, including sample preparation, injection, instrument operation, and troubleshooting. \n",
    "\n",
    "    7. Quality Control and Data Validation: Focuses on performance checks, validation criteria, and measures to ensure data reliability. \n",
    "\n",
    "    8. Data Analysis and Reporting: Describes how results should be processed, analyzed, and documented, often including specific formats or tools. \n",
    "\n",
    "    9. Limitations and Interferences: Identifies constraints of the method, such as compounds that may not be detected or interferences that could affect results. \n",
    "\n",
    "    10. Health and Environmental Safety: Emphasizes precautions to protect operators and minimize environmental impact during the procedure. \n",
    "\n",
    "    11. Documentation and References: Specifies record-keeping requirements and cites foundational literature or external standards that the SOP builds upon. \n",
    "\n",
    "    12. Special Precautions and Handling: Covers specific handling instructions for sensitive or hazardous materials used in the procedure. \n",
    "    Use the following context to create the '{section}' section for the SOP:\n",
    "    Context:\n",
    "    {context_text}\n",
    "\n",
    "    Section: {section}\n",
    "    \"\"\"\n",
    "    model = ChatOpenAI(model=\"gpt-4\", openai_api_key=API_KEY)\n",
    "    response = model.invoke(prompt)\n",
    "\n",
    "    return response.content if response else \"Error generating this section\"\n",
    "\n",
    "# Step 5: Extract content from PDF (without images)\n",
    "def extract_manual_content(pdf_path, max_pages=10):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = []\n",
    "\n",
    "    for page_num in range(min(len(doc), max_pages)):\n",
    "        page = doc[page_num]\n",
    "        text.append(page.get_text())\n",
    "\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "# Step 6: Save SOP to Word (without images)\n",
    "def save_sop_to_word(sop_text: str, output_file: str):\n",
    "    doc = WordDocument()\n",
    "    doc.add_heading(\"Standard Operating Procedure (SOP)\", level=1)\n",
    "\n",
    "    # Split SOP text into sections\n",
    "    sections = sop_text.split(\"\\n\\n\")\n",
    "    for section in sections:\n",
    "        if \":\" in section:\n",
    "            header, content = section.split(\":\", 1)\n",
    "            doc.add_heading(header.strip(), level=2)\n",
    "            doc.add_paragraph(content.strip())\n",
    "        else:\n",
    "            doc.add_paragraph(section.strip())\n",
    "\n",
    "    doc.save(output_file)\n",
    "    print(f\"SOP successfully saved to {output_file}\")\n",
    "\n",
    "# Step 7: Generate the full SOP\n",
    "def generate_full_sop(query_text: str, manual_file: str, output_file: str):\n",
    "    sop_text = \"\"\n",
    "    sop_sections = [\n",
    "        \"Scope\",\n",
    "        \"Background\",\n",
    "        \"Safety\",\n",
    "        \"Materials Required\",\n",
    "        \"Standards and Controls\",\n",
    "        \"Calibration\",\n",
    "        \"Procedures\",\n",
    "        \"Sampling\",\n",
    "        \"Calculations\",\n",
    "        \"Uncertainty of Measurement\",\n",
    "        \"Limitations\",\n",
    "        \"Documentation\",\n",
    "        \"References\",\n",
    "    ]\n",
    "\n",
    "    for section in sop_sections:\n",
    "        print(f\"Generating section: {section}\")\n",
    "        section_text = generate_sop_section(query_text, manual_file, section)\n",
    "        sop_text += f\"\\n\\n{section}:\\n{section_text}\"\n",
    "\n",
    "    save_sop_to_word(sop_text, output_file)\n",
    "    print(\"SOP generation completed.\")\n",
    "\n",
    "# Step 8: Hide one SOP\n",
    "def hide_sop(sop_name: str, source_dir: str, hidden_dir: str):\n",
    "    sop_path = os.path.join(source_dir, sop_name)\n",
    "    hidden_path = os.path.join(hidden_dir, sop_name)\n",
    "\n",
    "    if not os.path.exists(hidden_dir):\n",
    "        os.makedirs(hidden_dir)\n",
    "\n",
    "    if os.path.exists(sop_path):\n",
    "        try:\n",
    "            shutil.copy(sop_path, hidden_path)\n",
    "            os.remove(sop_path)\n",
    "            print(f\"SOP '{sop_name}' has been hidden.\")\n",
    "        except PermissionError as e:\n",
    "            print(f\"Permission error: {e}. Ensure the file is not open in another program.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred while hiding SOP: {e}\")\n",
    "    else:\n",
    "        print(f\"SOP '{sop_name}' not found in '{source_dir}'.\")\n",
    "\n",
    "# Step 9: Extract and Compare File Content\n",
    "def extract_text_from_docx(docx_path):\n",
    "    doc = WordDocument(docx_path)\n",
    "    text = []\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text.append(paragraph.text)\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = []\n",
    "    for page in doc:\n",
    "        text.append(page.get_text())\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "def calculate_similarity(file1_path: str, file2_path: str):\n",
    "    if file1_path.endswith('.docx'):\n",
    "        file1_content = extract_text_from_docx(file1_path)\n",
    "    elif file1_path.endswith('.pdf'):\n",
    "        file1_content = extract_text_from_pdf(file1_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {file1_path}\")\n",
    "\n",
    "    if file2_path.endswith('.docx'):\n",
    "        file2_content = extract_text_from_docx(file2_path)\n",
    "    elif file2_path.endswith('.pdf'):\n",
    "        file2_content = extract_text_from_pdf(file2_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {file2_path}\")\n",
    "\n",
    "    vectorizer = TfidfVectorizer().fit_transform([file1_content, file2_content])\n",
    "    vectors = vectorizer.toarray()\n",
    "    similarity = cosine_similarity(vectors)\n",
    "    return similarity[0, 1]\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    hide_sop(HIDDEN_SOP, DATA_PATH, \"hidden_sops\")\n",
    "\n",
    "    print(\"Step 1: Loading documents...\")\n",
    "    documents = load_documents()\n",
    "\n",
    "    print(\"Step 2: Splitting documents into chunks...\")\n",
    "    chunks = split_documents(documents)\n",
    "\n",
    "    print(\"Step 3: Adding chunks to Chroma database...\")\n",
    "    add_to_chroma(chunks)\n",
    "\n",
    "    print(\"Step 4: Generating SOP for an instrument...\")\n",
    "    instrument_query = \"Write the SOP for Shimadzu Gas chromatography mass spectrometer QP2010 SE Standard Operating Procedure\"\n",
    "    generate_full_sop(instrument_query, MANUAL_FILE, OUTPUT_FILE)\n",
    "\n",
    "    hidden_sop_path = os.path.join(\"hidden_sops\", HIDDEN_SOP)\n",
    "    similarity_score = calculate_similarity(OUTPUT_FILE, hidden_sop_path)\n",
    "    print(f\"Similarity score between generated and actual SOP: {similarity_score:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2b72cc4-caab-4370-b796-5d80c3749e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOP 'ICPMS_SOPs_Liquids.pdf' not found in 'SOPS'.\n",
      "Step 1: Loading documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "invalid pdf header: b'\\r\\n%PD'\n",
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 45 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Splitting documents into chunks...\n",
      "Step 3: Adding chunks to Chroma database...\n",
      "Step 4: Generating SOP for an instrument...\n",
      "Generating section: Scope\n",
      "Generating section: Background\n",
      "Generating section: Safety\n",
      "Generating section: Materials Required\n",
      "Generating section: Standards and Controls\n",
      "Generating section: Calibration\n",
      "Generating section: Procedures\n",
      "Generating section: Sampling\n",
      "Generating section: Calculations\n",
      "Generating section: Uncertainty of Measurement\n",
      "Generating section: Limitations\n",
      "Generating section: Documentation\n",
      "Generating section: References\n",
      "SOP successfully saved to Generated_SOP_for_ICP.docx\n",
      "SOP generation completed.\n",
      "Similarity score between generated and actual SOP: 0.84\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import fitz  # PyMuPDF for PDF processing\n",
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from docx import Document as WordDocument\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "CHROMA_PATH = \"chroma\"  # Path to Chroma database\n",
    "DATA_PATH = \"SOPS\"  # Path to SOPS directory\n",
    "HIDDEN_SOP = \"ICPMS_SOPs_Liquids.pdf\"  # Name of the hidden SOP file\n",
    "MANUAL_FILE = \"8510230100_700SeriesICP_UserManual.pdf\"  # Manual file\n",
    "OUTPUT_FILE = \"Generated_SOP_for_ICP.docx\"  # Output file\n",
    "API_KEY = \"private key\"\n",
    "\n",
    "# Step 1: Load documents\n",
    "def load_documents():\n",
    "    document_loader = PyPDFDirectoryLoader(DATA_PATH)\n",
    "    return document_loader.load()\n",
    "\n",
    "# Step 2: Split documents into chunks\n",
    "def split_documents(documents: list[Document]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=80, length_function=len)\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "# Step 3: Create or update Chroma database\n",
    "def add_to_chroma(chunks: list[Document]):\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=get_embedding_function())\n",
    "    db.add_documents(chunks)\n",
    "    db.persist()\n",
    "\n",
    "# Embedding function\n",
    "def get_embedding_function():\n",
    "    return OpenAIEmbeddings(openai_api_key=API_KEY)\n",
    "\n",
    "# Step 4: Generate a single SOP section\n",
    "def generate_sop_section(query_text: str, manual_file: str, section: str):\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=get_embedding_function())\n",
    "\n",
    "    # Retrieve relevant chunks\n",
    "    results = db.similarity_search_with_score(query_text, k=3)\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _ in results])\n",
    "\n",
    "    # Extract manual content\n",
    "    manual_text = extract_manual_content(manual_file, max_pages=10)\n",
    "    context_text += f\"\\n\\nManual Content:\\n{manual_text[:2000]}\"  # Include snippet of manual content\n",
    "\n",
    "    # Generate the section\n",
    "    prompt = f\"\"\"\n",
    "     # Updated prompt\n",
    "    prompt = f\"\"\n",
    "    Include comprehensive details for each section, including examples, explanations, and visuals. Don't summarize the details and keep the ideas unique and not redundant. Use step-by-step style in writing the process. Dont ask the user to refer to manufacture manual like saying “.Follow the manufacturer’s guidelines for calibration procedures” \n",
    "\n",
    "Structure: \n",
    "\n",
    "    1. Scope: Defines the purpose and applicability of the procedure, Listing all  uses , applications and  analysis methods that could be done on this instrument, such as analyzing air samples, tobacco content, or hydrocarbons in automotive exhaust.  Specifies the sample types that instrument can measure , the detection limit in (mg/Kg) and the method spike recovery , if applicable. Defines the exclusions. Use bullet point style of writing.  \n",
    "\n",
    "    2. Background: Provides context or rationale for the method being standardized, reference related research or industry needs.  Explain the meaning of the instrument signals to help the user understand and correlate the analysis. List the abbreviation and definitions in a tabular format. List the previous models of the same device.  \n",
    "\n",
    "    3. Safety: describe point by point all safety precautions, including General precaution, operation precautions and list the personal protective equipment's (PPE) needed, Listing all possible hazardous chemicals used with this instrument. Describe step-by-stepwaste disposal protocols. Use the following paragraph between square brackets as an example for  \n",
    "\n",
    "[General laboratory precautions  \n",
    "\n",
    "Avoid leaks in the carrier gas lines. Use leak-checking equipment to periodically check for hydrogen leaks. • Eliminate from your laboratory as many ignition sources as possible (for example, open flames, devices that can spark and sources of static electricity). • Do not allow hydrogen from a high pressure cylinder to vent directly to atmosphere (danger of self-ignition). • Use a hydrogen generator instead of bottled hydrogen. Operating precautions • Turn off the hydrogen at its source every time you shut down the GC or MS. • Do not use hydrogen as a collision cell gas. Turn off the hydrogen at its source every time you vent the MS (do not heat the capillary column without carrier gas flow). • Turn off the hydrogen at its source every time shutoff valves in the MS are closed (do not heat the capillary column without carrier gas flow). • Turn off the hydrogen at its source if a power failure occurs. • If a power failure occurs while the GC/MS system is unattended, even if the system has restarted by itself:  Immediately turn off the hydrogen at its source.  Turn off the GC.  Turn off the MS and allow it to cool for 1 hour.  Eliminate all potential sources of ignition in the room.  Open the vacuum manifold of the MS to atmosphere.  Wait at least 10 minutes to allow any hydrogen to dissipate.  Start up the GC and MS as normal. When using hydrogen gas, check the system for leaks to prevent possible fire and explosion hazards based on local Environmental Health and Safety (EHS) requirements. Always check for leaks after changing a tank or servicing the gas lines. Always make sure the vent line is vented into a fume hood.] \n",
    "\n",
    " \n",
    "\n",
    "   4. Materials and Equipment: First, Explain in bullets all the instruments' parts and auxiliary equipment. Include samples and consumables materials in two sections.  Lists all necessary reagents, solvents, instrumentation, and ancillary tools required for conducting the procedure. Write it in a bullets style.  \n",
    "\n",
    "    5. Standards and Calibration: Details the required reference materials, standards for quality control, and steps for instrument calibration to ensure accuracy. \n",
    "\n",
    "    6. Procedure: Offers step-by-step instructions for conducting the analysis, including sample preparation, injection, instrument operation, and troubleshooting. \n",
    "\n",
    "    7. Quality Control and Data Validation: Focuses on performance checks, validation criteria, and measures to ensure data reliability. \n",
    "\n",
    "    8. Data Analysis and Reporting: Describes how results should be processed, analyzed, and documented, often including specific formats or tools. \n",
    "\n",
    "    9. Limitations and Interferences: Identifies constraints of the method, such as compounds that may not be detected or interferences that could affect results. \n",
    "\n",
    "    10. Health and Environmental Safety: Emphasizes precautions to protect operators and minimize environmental impact during the procedure. \n",
    "\n",
    "    11. Documentation and References: Specifies record-keeping requirements and cites foundational literature or external standards that the SOP builds upon. \n",
    "\n",
    "    12. Special Precautions and Handling: Covers specific handling instructions for sensitive or hazardous materials used in the procedure. \n",
    "    Use the following context to create the '{section}' section for the SOP:\n",
    "    Context:\n",
    "    {context_text}\n",
    "\n",
    "    Section: {section}\n",
    "    \"\"\"\n",
    "    \n",
    "    model = ChatOpenAI(model=\"gpt-4\", openai_api_key=API_KEY)\n",
    "    response = model.invoke(prompt)\n",
    "\n",
    "    return response.content if response else \"Error generating this section\"\n",
    "\n",
    "# Step 5: Extract content from PDF (without images)\n",
    "def extract_manual_content(pdf_path, max_pages=10):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = []\n",
    "\n",
    "    for page_num in range(min(len(doc), max_pages)):\n",
    "        page = doc[page_num]\n",
    "        text.append(page.get_text())\n",
    "\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "# Step 6: Save SOP to Word (without images)\n",
    "def save_sop_to_word(sop_text: str, output_file: str):\n",
    "    doc = WordDocument()\n",
    "    doc.add_heading(\"Standard Operating Procedure (SOP)\", level=1)\n",
    "\n",
    "    # Split SOP text into sections\n",
    "    sections = sop_text.split(\"\\n\\n\")\n",
    "    for section in sections:\n",
    "        if \":\" in section:\n",
    "            header, content = section.split(\":\", 1)\n",
    "            doc.add_heading(header.strip(), level=2)\n",
    "            doc.add_paragraph(content.strip())\n",
    "        else:\n",
    "            doc.add_paragraph(section.strip())\n",
    "\n",
    "    doc.save(output_file)\n",
    "    print(f\"SOP successfully saved to {output_file}\")\n",
    "\n",
    "# Step 7: Generate the full SOP\n",
    "def generate_full_sop(query_text: str, manual_file: str, output_file: str):\n",
    "    sop_text = \"\"\n",
    "    sop_sections = [\n",
    "        \"Scope\",\n",
    "        \"Background\",\n",
    "        \"Safety\",\n",
    "        \"Materials Required\",\n",
    "        \"Standards and Controls\",\n",
    "        \"Calibration\",\n",
    "        \"Procedures\",\n",
    "        \"Sampling\",\n",
    "        \"Calculations\",\n",
    "        \"Uncertainty of Measurement\",\n",
    "        \"Limitations\",\n",
    "        \"Documentation\",\n",
    "        \"References\",\n",
    "    ]\n",
    "\n",
    "    for section in sop_sections:\n",
    "        print(f\"Generating section: {section}\")\n",
    "        section_text = generate_sop_section(query_text, manual_file, section)\n",
    "        sop_text += f\"\\n\\n{section}:\\n{section_text}\"\n",
    "\n",
    "    save_sop_to_word(sop_text, output_file)\n",
    "    print(\"SOP generation completed.\")\n",
    "\n",
    "# Step 8: Hide one SOP\n",
    "def hide_sop(sop_name: str, source_dir: str, hidden_dir: str):\n",
    "    sop_path = os.path.join(source_dir, sop_name)\n",
    "    hidden_path = os.path.join(hidden_dir, sop_name)\n",
    "\n",
    "    if not os.path.exists(hidden_dir):\n",
    "        os.makedirs(hidden_dir)\n",
    "\n",
    "    if os.path.exists(sop_path):\n",
    "        try:\n",
    "            shutil.copy(sop_path, hidden_path)\n",
    "            os.remove(sop_path)\n",
    "            print(f\"SOP '{sop_name}' has been hidden.\")\n",
    "        except PermissionError as e:\n",
    "            print(f\"Permission error: {e}. Ensure the file is not open in another program.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred while hiding SOP: {e}\")\n",
    "    else:\n",
    "        print(f\"SOP '{sop_name}' not found in '{source_dir}'.\")\n",
    "\n",
    "# Step 9: Extract and Compare File Content\n",
    "def extract_text_from_docx(docx_path):\n",
    "    doc = WordDocument(docx_path)\n",
    "    text = []\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text.append(paragraph.text)\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = []\n",
    "    for page in doc:\n",
    "        text.append(page.get_text())\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "def calculate_similarity(file1_path: str, file2_path: str):\n",
    "    if file1_path.endswith('.docx'):\n",
    "        file1_content = extract_text_from_docx(file1_path)\n",
    "    elif file1_path.endswith('.pdf'):\n",
    "        file1_content = extract_text_from_pdf(file1_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {file1_path}\")\n",
    "\n",
    "    if file2_path.endswith('.docx'):\n",
    "        file2_content = extract_text_from_docx(file2_path)\n",
    "    elif file2_path.endswith('.pdf'):\n",
    "        file2_content = extract_text_from_pdf(file2_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {file2_path}\")\n",
    "\n",
    "    vectorizer = TfidfVectorizer().fit_transform([file1_content, file2_content])\n",
    "    vectors = vectorizer.toarray()\n",
    "    similarity = cosine_similarity(vectors)\n",
    "    return similarity[0, 1]\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    hide_sop(HIDDEN_SOP, DATA_PATH, \"hidden_sops\")\n",
    "\n",
    "    print(\"Step 1: Loading documents...\")\n",
    "    documents = load_documents()\n",
    "\n",
    "    print(\"Step 2: Splitting documents into chunks...\")\n",
    "    chunks = split_documents(documents)\n",
    "\n",
    "    print(\"Step 3: Adding chunks to Chroma database...\")\n",
    "    add_to_chroma(chunks)\n",
    "\n",
    "    print(\"Step 4: Generating SOP for an instrument...\")\n",
    "    instrument_query = \"Write the SOP for ICPMS Liquids\"\n",
    "    generate_full_sop(instrument_query, MANUAL_FILE, OUTPUT_FILE)\n",
    "\n",
    "    hidden_sop_path = os.path.join(\"hidden_sops\", HIDDEN_SOP)\n",
    "    similarity_score = calculate_similarity(OUTPUT_FILE, hidden_sop_path)\n",
    "    print(f\"Similarity score between generated and actual SOP: {similarity_score:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7928853-7369-45b6-b448-9f9d0df5f533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOP 'SOP_FTIR.pdf' has been hidden.\n",
      "Step 1: Loading documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "invalid pdf header: b'\\r\\n%PD'\n",
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 45 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Splitting documents into chunks...\n",
      "Step 3: Adding chunks to Chroma database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roxan\\AppData\\Local\\Temp\\ipykernel_4532\\1373116906.py:39: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  return OpenAIEmbeddings(openai_api_key=API_KEY)\n",
      "C:\\Users\\roxan\\AppData\\Local\\Temp\\ipykernel_4532\\1373116906.py:33: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(persist_directory=CHROMA_PATH, embedding_function=get_embedding_function())\n",
      "C:\\Users\\roxan\\AppData\\Local\\Temp\\ipykernel_4532\\1373116906.py:35: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Generating SOP for an instrument...\n",
      "Generating section: Scope\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roxan\\AppData\\Local\\Temp\\ipykernel_4532\\1373116906.py:95: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  model = ChatOpenAI(model=\"gpt-4\", openai_api_key=API_KEY)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating section: Background\n",
      "Generating section: Safety\n",
      "Generating section: Materials Required\n",
      "Generating section: Standards and Controls\n",
      "Generating section: Calibration\n",
      "Generating section: Procedures\n",
      "Generating section: Sampling\n",
      "Generating section: Calculations\n",
      "Generating section: Uncertainty of Measurement\n",
      "Generating section: Limitations\n",
      "Generating section: Documentation\n",
      "Generating section: References\n",
      "SOP successfully saved to Genrated_SOP_FTIR.docx\n",
      "SOP generation completed.\n",
      "Similarity score between generated and actual SOP: 0.73\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import fitz  # PyMuPDF for PDF processing\n",
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from docx import Document as WordDocument\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "CHROMA_PATH = \"chroma\"  # Path to Chroma database\n",
    "DATA_PATH = \"SOPS\"  # Path to SOPS directory\n",
    "HIDDEN_SOP = \"SOP_FTIR.pdf\"  # Name of the hidden SOP file\n",
    "MANUAL_FILE = \"\"  # Manual file\n",
    "OUTPUT_FILE = \"Genrated_SOP_FTIR.docx\"  # Output file\n",
    "API_KEY = \"private key\"\n",
    "\n",
    "# Step 1: Load documents\n",
    "def load_documents():\n",
    "    document_loader = PyPDFDirectoryLoader(DATA_PATH)\n",
    "    return document_loader.load()\n",
    "\n",
    "# Step 2: Split documents into chunks\n",
    "def split_documents(documents: list[Document]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=80, length_function=len)\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "# Step 3: Create or update Chroma database\n",
    "def add_to_chroma(chunks: list[Document]):\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=get_embedding_function())\n",
    "    db.add_documents(chunks)\n",
    "    db.persist()\n",
    "\n",
    "# Embedding function\n",
    "def get_embedding_function():\n",
    "    return OpenAIEmbeddings(openai_api_key=API_KEY)\n",
    "\n",
    "# Step 4: Generate a single SOP section\n",
    "def generate_sop_section(query_text: str, manual_file: str, section: str):\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=get_embedding_function())\n",
    "\n",
    "    # Retrieve relevant chunks\n",
    "    results = db.similarity_search_with_score(query_text, k=3)\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _ in results])\n",
    "\n",
    "    # Extract manual content\n",
    "    manual_text = extract_manual_content(manual_file, max_pages=10)\n",
    "    context_text += f\"\\n\\nManual Content:\\n{manual_text[:2000]}\"  # Include snippet of manual content\n",
    "\n",
    "    # Generate the section\n",
    "    prompt = f\"\"\"\n",
    "     # Updated prompt\n",
    "    prompt = f\"\"\n",
    "    Include comprehensive details for each section, including examples, explanations, and visuals. Don't summarize the details and keep the ideas unique and not redundant. Use step-by-step style in writing the process. Dont ask the user to refer to manufacture manual like saying “.Follow the manufacturer’s guidelines for calibration procedures” \n",
    "\n",
    "Structure: \n",
    "\n",
    "    1. Scope: Defines the purpose and applicability of the procedure, Listing all  uses , applications and  analysis methods that could be done on this instrument, such as analyzing air samples, tobacco content, or hydrocarbons in automotive exhaust.  Specifies the sample types that instrument can measure , the detection limit in (mg/Kg) and the method spike recovery , if applicable. Defines the exclusions. Use bullet point style of writing.  \n",
    "\n",
    "    2. Background: Provides context or rationale for the method being standardized, reference related research or industry needs.  Explain the meaning of the instrument signals to help the user understand and correlate the analysis. List the abbreviation and definitions in a tabular format. List the previous models of the same device.  \n",
    "\n",
    "    3. Safety: describe point by point all safety precautions, including General precaution, operation precautions and list the personal protective equipment's (PPE) needed, Listing all possible hazardous chemicals used with this instrument. Describe step-by-stepwaste disposal protocols. Use the following paragraph between square brackets as an example for  \n",
    "\n",
    "[General laboratory precautions  \n",
    "\n",
    "Avoid leaks in the carrier gas lines. Use leak-checking equipment to periodically check for hydrogen leaks. • Eliminate from your laboratory as many ignition sources as possible (for example, open flames, devices that can spark and sources of static electricity). • Do not allow hydrogen from a high pressure cylinder to vent directly to atmosphere (danger of self-ignition). • Use a hydrogen generator instead of bottled hydrogen. Operating precautions • Turn off the hydrogen at its source every time you shut down the GC or MS. • Do not use hydrogen as a collision cell gas. Turn off the hydrogen at its source every time you vent the MS (do not heat the capillary column without carrier gas flow). • Turn off the hydrogen at its source every time shutoff valves in the MS are closed (do not heat the capillary column without carrier gas flow). • Turn off the hydrogen at its source if a power failure occurs. • If a power failure occurs while the GC/MS system is unattended, even if the system has restarted by itself:  Immediately turn off the hydrogen at its source.  Turn off the GC.  Turn off the MS and allow it to cool for 1 hour.  Eliminate all potential sources of ignition in the room.  Open the vacuum manifold of the MS to atmosphere.  Wait at least 10 minutes to allow any hydrogen to dissipate.  Start up the GC and MS as normal. When using hydrogen gas, check the system for leaks to prevent possible fire and explosion hazards based on local Environmental Health and Safety (EHS) requirements. Always check for leaks after changing a tank or servicing the gas lines. Always make sure the vent line is vented into a fume hood.] \n",
    "\n",
    " \n",
    "\n",
    "   4. Materials and Equipment: First, Explain in bullets all the instruments' parts and auxiliary equipment. Include samples and consumables materials in two sections.  Lists all necessary reagents, solvents, instrumentation, and ancillary tools required for conducting the procedure. Write it in a bullets style.  \n",
    "\n",
    "    5. Standards and Calibration: Details the required reference materials, standards for quality control, and steps for instrument calibration to ensure accuracy. \n",
    "\n",
    "    6. Procedure: Offers step-by-step instructions for conducting the analysis, including sample preparation, injection, instrument operation, and troubleshooting. \n",
    "\n",
    "    7. Quality Control and Data Validation: Focuses on performance checks, validation criteria, and measures to ensure data reliability. \n",
    "\n",
    "    8. Data Analysis and Reporting: Describes how results should be processed, analyzed, and documented, often including specific formats or tools. \n",
    "\n",
    "    9. Limitations and Interferences: Identifies constraints of the method, such as compounds that may not be detected or interferences that could affect results. \n",
    "\n",
    "    10. Health and Environmental Safety: Emphasizes precautions to protect operators and minimize environmental impact during the procedure. \n",
    "\n",
    "    11. Documentation and References: Specifies record-keeping requirements and cites foundational literature or external standards that the SOP builds upon. \n",
    "\n",
    "    12. Special Precautions and Handling: Covers specific handling instructions for sensitive or hazardous materials used in the procedure. \n",
    "    Use the following context to create the '{section}' section for the SOP:\n",
    "    Context:\n",
    "\n",
    "    Section: {section}\n",
    "    \"\"\"\n",
    "    model = ChatOpenAI(model=\"gpt-4\", openai_api_key=API_KEY)\n",
    "    response = model.invoke(prompt)\n",
    "\n",
    "    return response.content if response else \"Error generating this section\"\n",
    "\n",
    "# Step 5: Extract content from PDF (without images)\n",
    "def extract_manual_content(pdf_path, max_pages=10):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = []\n",
    "\n",
    "    for page_num in range(min(len(doc), max_pages)):\n",
    "        page = doc[page_num]\n",
    "        text.append(page.get_text())\n",
    "\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "# Step 6: Save SOP to Word (without images)\n",
    "def save_sop_to_word(sop_text: str, output_file: str):\n",
    "    doc = WordDocument()\n",
    "    doc.add_heading(\"Standard Operating Procedure (SOP)\", level=1)\n",
    "\n",
    "    # Split SOP text into sections\n",
    "    sections = sop_text.split(\"\\n\\n\")\n",
    "    for section in sections:\n",
    "        if \":\" in section:\n",
    "            header, content = section.split(\":\", 1)\n",
    "            doc.add_heading(header.strip(), level=2)\n",
    "            doc.add_paragraph(content.strip())\n",
    "        else:\n",
    "            doc.add_paragraph(section.strip())\n",
    "\n",
    "    doc.save(output_file)\n",
    "    print(f\"SOP successfully saved to {output_file}\")\n",
    "\n",
    "# Step 7: Generate the full SOP\n",
    "def generate_full_sop(query_text: str, manual_file: str, output_file: str):\n",
    "    sop_text = \"\"\n",
    "    sop_sections = [\n",
    "        \"Scope\",\n",
    "        \"Background\",\n",
    "        \"Safety\",\n",
    "        \"Materials Required\",\n",
    "        \"Standards and Controls\",\n",
    "        \"Calibration\",\n",
    "        \"Procedures\",\n",
    "        \"Sampling\",\n",
    "        \"Calculations\",\n",
    "        \"Uncertainty of Measurement\",\n",
    "        \"Limitations\",\n",
    "        \"Documentation\",\n",
    "        \"References\",\n",
    "    ]\n",
    "\n",
    "    for section in sop_sections:\n",
    "        print(f\"Generating section: {section}\")\n",
    "        section_text = generate_sop_section(query_text, manual_file, section)\n",
    "        sop_text += f\"\\n\\n{section}:\\n{section_text}\"\n",
    "\n",
    "    save_sop_to_word(sop_text, output_file)\n",
    "    print(\"SOP generation completed.\")\n",
    "\n",
    "# Step 8: Hide one SOP\n",
    "def hide_sop(sop_name: str, source_dir: str, hidden_dir: str):\n",
    "    sop_path = os.path.join(source_dir, sop_name)\n",
    "    hidden_path = os.path.join(hidden_dir, sop_name)\n",
    "\n",
    "    if not os.path.exists(hidden_dir):\n",
    "        os.makedirs(hidden_dir)\n",
    "\n",
    "    if os.path.exists(sop_path):\n",
    "        try:\n",
    "            shutil.copy(sop_path, hidden_path)\n",
    "            os.remove(sop_path)\n",
    "            print(f\"SOP '{sop_name}' has been hidden.\")\n",
    "        except PermissionError as e:\n",
    "            print(f\"Permission error: {e}. Ensure the file is not open in another program.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred while hiding SOP: {e}\")\n",
    "    else:\n",
    "        print(f\"SOP '{sop_name}' not found in '{source_dir}'.\")\n",
    "\n",
    "# Step 9: Extract and Compare File Content\n",
    "def extract_text_from_docx(docx_path):\n",
    "    doc = WordDocument(docx_path)\n",
    "    text = []\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text.append(paragraph.text)\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = []\n",
    "    for page in doc:\n",
    "        text.append(page.get_text())\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "def calculate_similarity(file1_path: str, file2_path: str):\n",
    "    if file1_path.endswith('.docx'):\n",
    "        file1_content = extract_text_from_docx(file1_path)\n",
    "    elif file1_path.endswith('.pdf'):\n",
    "        file1_content = extract_text_from_pdf(file1_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {file1_path}\")\n",
    "\n",
    "    if file2_path.endswith('.docx'):\n",
    "        file2_content = extract_text_from_docx(file2_path)\n",
    "    elif file2_path.endswith('.pdf'):\n",
    "        file2_content = extract_text_from_pdf(file2_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {file2_path}\")\n",
    "\n",
    "    vectorizer = TfidfVectorizer().fit_transform([file1_content, file2_content])\n",
    "    vectors = vectorizer.toarray()\n",
    "    similarity = cosine_similarity(vectors)\n",
    "    return similarity[0, 1]\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    hide_sop(HIDDEN_SOP, DATA_PATH, \"hidden_sops\")\n",
    "\n",
    "    print(\"Step 1: Loading documents...\")\n",
    "    documents = load_documents()\n",
    "\n",
    "    print(\"Step 2: Splitting documents into chunks...\")\n",
    "    chunks = split_documents(documents)\n",
    "\n",
    "    print(\"Step 3: Adding chunks to Chroma database...\")\n",
    "    add_to_chroma(chunks)\n",
    "\n",
    "    print(\"Step 4: Generating SOP for an instrument...\")\n",
    "    instrument_query = \"Write the SOP for the Perkin Elmer model 1600 FTIR.\"\n",
    "    generate_full_sop(instrument_query, MANUAL_FILE, OUTPUT_FILE)\n",
    "\n",
    "    hidden_sop_path = os.path.join(\"hidden_sops\", HIDDEN_SOP)\n",
    "    similarity_score = calculate_similarity(OUTPUT_FILE, hidden_sop_path)\n",
    "    print(f\"Similarity score between generated and actual SOP: {similarity_score:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55505c5-be90-47f6-9a69-b00cbab7f304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa7f159-f959-4b8a-95b0-dd06d1cb48f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec40c31-c3d8-407c-adbc-7cde570d302d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4a5ee8-0afe-42ed-a993-a6c4b1fb1168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2600203-d8ac-45ee-b0c4-c96c426ba545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18562067-75d0-4974-b24d-e1aa0ca1df82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dcedd5-f9f6-4e12-b29f-91f33252333d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e31fe4-a41c-40d4-bda3-035f15412e39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
